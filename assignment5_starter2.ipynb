{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KNN class\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Store the training data\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions based on the nearest neighbors' weighted average.\"\"\"\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Compute the distance matrix using the specified metric\n",
    "        distances = self.compute_distance(X, self.X)\n",
    "        \n",
    "        predictions = []\n",
    "        # Loop through each test point to make predictions\n",
    "        for i in range(X.shape[0]):\n",
    "            # Get indices of k nearest neighbors\n",
    "            nearest_neighbors_indices = np.argsort(distances[i])[:self.k]\n",
    "            nearest_labels = self.y[nearest_neighbors_indices]\n",
    "            nearest_distances = distances[i][nearest_neighbors_indices]\n",
    "    \n",
    "            # Compute weights as the inverse square of the distance\n",
    "            weights = 1 / (nearest_distances ** 2 + 1e-10)  # Add small value to avoid division by zero\n",
    "            \n",
    "            # Calculate the weighted average of the neighbors' labels\n",
    "            weighted_average = np.sum(nearest_labels * weights) / np.sum(weights)\n",
    "            \n",
    "            # Append the weighted average as the prediction\n",
    "            predictions.append(weighted_average)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "    def compute_distance(self, X1, X2):\n",
    "        \"\"\"Compute distance matrix based on the selected distance metric.\"\"\"\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            # Step 1: Compute squared sum of each row in X_test and X_train\n",
    "            X_test_squared = np.sum(np.square(X1), axis=1).reshape(-1, 1)\n",
    "            X_train_squared = np.sum(np.square(X2), axis=1).reshape(1, -1)\n",
    "        \n",
    "            # Step 2: Compute the dot product between X_test and X_train\n",
    "            cross_term = np.dot(X1, X2.T)\n",
    "        \n",
    "            # Step 3: Compute the full distance matrix\n",
    "            distances = np.sqrt(X_test_squared + X_train_squared - 2 * cross_term)\n",
    "        \n",
    "            return distances\n",
    "        \n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            # Manhattan distance computation\n",
    "            return np.sum(np.abs(X1[:, np.newaxis] - X2), axis=2)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported distance metric: {self.distance_metric}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imputation and scaling helper functions\n",
    "def impute_mean(column):\n",
    "    \"\"\"Replace missing numerical values with the column mean.\"\"\"\n",
    "    return column.fillna(column.mean())\n",
    "\n",
    "def min_max_scale(df):\n",
    "    \"\"\"Apply Min-Max scaling to the DataFrame.\"\"\"\n",
    "    return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "def impute_most_frequent(column):\n",
    "    \"\"\"Replace missing categorical values with the most frequent value.\"\"\"\n",
    "    return column.fillna(column.mode()[0])\n",
    "\n",
    "def one_hot_encode(df, categorical_features):\n",
    "    \"\"\"Perform one-hot encoding for categorical features.\"\"\"\n",
    "    for feature in categorical_features:\n",
    "        one_hot = pd.get_dummies(df[feature], prefix=feature)\n",
    "        df = pd.concat([df.drop(columns=[feature]), one_hot], axis=1)\n",
    "    return df\n",
    "\n",
    "# SVD function from scratch\n",
    "def svd(X, n_components):\n",
    "    \"\"\"Apply Singular Value Decomposition (SVD) for dimensionality reduction.\"\"\"\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    U, S, Vt = np.linalg.svd(X_centered, full_matrices=False)\n",
    "    X_reduced = np.dot(U[:, :n_components], np.diag(S[:n_components]))\n",
    "    return X_reduced\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(train_path, test_path, n_components=None):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "\n",
    "    # Separate features and target variable in training data\n",
    "    X_train = train_data.drop(columns=['Exited'])\n",
    "    y_train = train_data['Exited']\n",
    "\n",
    "    # Define numerical, categorical, and binary columns\n",
    "    numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "    categorical_features = ['Geography']\n",
    "    binary_features = ['HasCrCard', 'IsActiveMember', 'Gender']\n",
    "\n",
    "    # Convert binary features to binary (0 or 1) encoding for Gender\n",
    "    X_train['Gender'] = X_train['Gender'].map({'Male': 0, 'Female': 1})\n",
    "    test_data['Gender'] = test_data['Gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "    # Preprocess numerical features (Impute missing values)\n",
    "    X_train[numerical_features] = X_train[numerical_features].apply(impute_mean)\n",
    "    test_data[numerical_features] = test_data[numerical_features].apply(impute_mean)\n",
    "\n",
    "    # Scale numerical features\n",
    "    X_train[numerical_features] = min_max_scale(X_train[numerical_features])\n",
    "    test_data[numerical_features] = min_max_scale(test_data[numerical_features])\n",
    "\n",
    "    # One-hot encode categorical features (e.g., Geography)\n",
    "    X_train = one_hot_encode(X_train, categorical_features)\n",
    "    test_data = one_hot_encode(test_data, categorical_features)\n",
    "\n",
    "    # Align train and test columns (to handle any discrepancies after encoding)\n",
    "    X_train, test_data = X_train.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "    # Ensure all values are numeric before applying SVD\n",
    "    X_train = X_train.select_dtypes(include=[np.number])\n",
    "    test_data = test_data.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Apply SVD if n_components is specified\n",
    "    if n_components is not None:\n",
    "        X_train = svd(X_train.values, n_components)\n",
    "        test_data = svd(test_data.values, n_components)\n",
    "\n",
    "    return X_train, y_train, test_data\n",
    "\n",
    "# Example usage\n",
    "X_train, y_train, X_test = preprocess_data('train.csv', 'test.csv', n_components=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_score(y_true, y_pred_proba):\n",
    "        \"\"\"\n",
    "        Compute ROC AUC score for binary classification from scratch.\n",
    "    \n",
    "        Parameters:\n",
    "        - y_true: True binary labels (0 or 1)\n",
    "        - y_pred_proba: Predicted probabilities for the positive class (1)\n",
    "    \n",
    "        Returns:\n",
    "        - auc: Calculated ROC AUC score\n",
    "        \"\"\"\n",
    "        # Convert y_true and y_pred_proba to numpy arrays to avoid index issues\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred_proba = np.array(y_pred_proba)\n",
    "    \n",
    "        # Sort by predicted probabilities\n",
    "        sorted_indices = np.argsort(y_pred_proba)\n",
    "        y_true_sorted = y_true[sorted_indices]\n",
    "        y_pred_proba_sorted = y_pred_proba[sorted_indices]\n",
    "    \n",
    "        # Initialize variables\n",
    "        tpr_values = []\n",
    "        fpr_values = []\n",
    "        \n",
    "        n_pos = np.sum(y_true == 1)  # Number of positives (class 1)\n",
    "        n_neg = len(y_true) - n_pos  # Number of negatives (class 0)\n",
    "        \n",
    "        tp = 0\n",
    "        fp = 0\n",
    "    \n",
    "        # Loop through sorted probabilities and calculate TPR and FPR at each threshold\n",
    "        for i in range(len(y_true_sorted)):\n",
    "            if y_true_sorted[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "            tpr_values.append(tp / n_pos)\n",
    "            fpr_values.append(fp / n_neg)\n",
    "    \n",
    "        # Compute the area under the curve (AUC) using the trapezoidal rule\n",
    "        auc = 0.0\n",
    "        for i in range(1, len(tpr_values)):\n",
    "            auc += (fpr_values[i] - fpr_values[i - 1]) * (tpr_values[i] + tpr_values[i - 1]) / 2\n",
    "    \n",
    "        return auc\n",
    "\n",
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on the KNN classifier and calculate the ROC AUC score.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Feature matrix (numpy array)\n",
    "    - y: Labels (numpy array)\n",
    "    - knn: KNN model\n",
    "    - n_splits: Number of folds for cross-validation\n",
    "\n",
    "    Returns:\n",
    "    - mean_auc_score: The average ROC AUC score over the cross-validation folds.\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    fold_size = n_samples // n_splits\n",
    "    auc_scores = []\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        # Create validation set\n",
    "        X_val = X[i * fold_size:(i + 1) * fold_size]\n",
    "        y_val = y[i * fold_size:(i + 1) * fold_size]\n",
    "\n",
    "        # Create training set (everything except the validation fold)\n",
    "        X_train = np.concatenate((X[:i * fold_size], X[(i + 1) * fold_size:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]), axis=0)\n",
    "\n",
    "        # Fit the KNN model on the training data\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        # Get predicted probabilities for the validation set\n",
    "        y_pred_proba = knn.predict(X_val)\n",
    "\n",
    "        # Compute the ROC AUC score for the validation set\n",
    "        auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "    # Return the average AUC score over all splits\n",
    "    mean_auc_score = np.mean(auc_scores)\n",
    "    return mean_auc_score\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: 0.49109208049619324\n",
      "k=1, Cross-validation score: 0.49465755138647066\n",
      "k=2, Cross-validation score: 0.49359352995948924\n",
      "k=3, Cross-validation score: 0.4902041294579652\n",
      "k=4, Cross-validation score: 0.4893628624238439\n",
      "k=5, Cross-validation score: 0.49109208049619324\n",
      "k=6, Cross-validation score: 0.4895181237570547\n",
      "k=7, Cross-validation score: 0.4888734439414154\n",
      "k=8, Cross-validation score: 0.4902231140059793\n",
      "k=9, Cross-validation score: 0.48913943721881636\n",
      "k=10, Cross-validation score: 0.4864620588807008\n",
      "k=11, Cross-validation score: 0.48614168061593566\n",
      "k=12, Cross-validation score: 0.48393160614225206\n",
      "k=13, Cross-validation score: 0.485177353294221\n",
      "k=14, Cross-validation score: 0.4876273110620885\n",
      "k=15, Cross-validation score: 0.48728428934379703\n",
      "k=16, Cross-validation score: 0.4904829280234182\n",
      "k=17, Cross-validation score: 0.48846165270426695\n",
      "k=18, Cross-validation score: 0.4877013666901059\n",
      "k=19, Cross-validation score: 0.4871657864931664\n",
      "k=20, Cross-validation score: 0.4897183273144877\n",
      "Best k: 1 with cross-validation score: 0.49465755138647066\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "# Create and evaluate model\n",
    "knn = KNN(k=5, distance_metric='euclidean')\n",
    "\n",
    "# Perform cross-validation to evaluate model\n",
    "cv_scores = cross_validate(X, y, knn)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# Hyperparameter tuning (you can adjust k and evaluate different values)\n",
    "best_k = None\n",
    "best_score = 0\n",
    "\n",
    "for k in range(1, 21):  # Try different values of k\n",
    "    knn = KNN(k=k, distance_metric='euclidean')\n",
    "    cv_score = cross_validate(X, y, knn)\n",
    "    print(f\"k={k}, Cross-validation score: {cv_score}\")\n",
    "    if cv_score > best_score:\n",
    "        best_score = cv_score\n",
    "        best_k = k\n",
    "\n",
    "print(f\"Best k: {best_k} with cross-validation score: {best_score}\")\n",
    "\n",
    "# Train on full dataset with optimal hyperparameters (best k) and make predictions on test set\n",
    "knn = KNN(k=best_k, distance_metric='euclidean')\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = knn.predict(X_test)\n",
    "\n",
    "# Save test predictions\n",
    "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
