{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KNN class\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Store the training data\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions based on the nearest neighbors (fraction of neighbors that are 1).\"\"\"\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Compute the distance matrix using the specified metric\n",
    "        distances = self.compute_distance(X, self.X)\n",
    "        \n",
    "        predictions = []\n",
    "        # Loop through each test point to make predictions\n",
    "        for i in range(X.shape[0]):\n",
    "            # Get indices of k nearest neighbors\n",
    "            nearest_neighbors_indices = np.argsort(distances[i])[:self.k]\n",
    "            nearest_labels = self.y[nearest_neighbors_indices]\n",
    "            nearest_distances = distances[i][nearest_neighbors_indices]\n",
    "    \n",
    "            # Compute weights as the inverse square of the distance\n",
    "            weights = 1 / (nearest_distances ** 2 + 1e-10)  # Add small value to avoid division by zero\n",
    "            \n",
    "            # Calculate the weighted sum for label 1\n",
    "            weighted_sum_label_1 = np.sum(weights[nearest_labels == 1])\n",
    "            weighted_sum_label_0 = np.sum(weights[nearest_labels == 0])\n",
    "\n",
    "            # Predict the label with the highest weighted sum\n",
    "            if weighted_sum_label_1 > weighted_sum_label_0:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "        \n",
    "    def compute_distance(self, X1, X2):\n",
    "        \"\"\"Compute distance matrix based on the selected distance metric.\"\"\"\n",
    "    # Step 1: Compute squared sum of each row in X_test and X_train\n",
    "        X_test_squared = np.sum(np.square(X1), axis=1).reshape(-1, 1)\n",
    "        X_train_squared = np.sum(np.square(X2), axis=1).reshape(1, -1)\n",
    "        \n",
    "            # Step 2: Compute the dot product between X_test and X_train\n",
    "        cross_term = np.dot(X1, X2.T)\n",
    "        \n",
    "            # Step 3: Compute the full distance matrix\n",
    "        distances = np.sqrt(X_test_squared + X_train_squared - 2 * cross_term)\n",
    "        \n",
    "        return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mean(column):\n",
    "    \"\"\"Replace missing numerical values with the column mean.\"\"\"\n",
    "    return column.fillna(column.mean())\n",
    "\n",
    "def min_max_scale(df):\n",
    "    \"\"\"Apply Min-Max scaling to the DataFrame.\"\"\"\n",
    "    return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "def impute_most_frequent(column):\n",
    "    \"\"\"Replace missing categorical values with the most frequent value.\"\"\"\n",
    "    return column.fillna(column.mode()[0])\n",
    "\n",
    "def one_hot_encode(df, categorical_features):\n",
    "    \"\"\"Perform one-hot encoding for categorical features.\"\"\"\n",
    "    for feature in categorical_features:\n",
    "        one_hot = pd.get_dummies(df[feature], prefix=feature)\n",
    "        df = pd.concat([df.drop(columns=[feature]), one_hot], axis=1)\n",
    "    return df\n",
    "\n",
    "def standard_scale(X, mean=None, std=None):\n",
    "    \"\"\"Standardize features by removing the mean and scaling to unit variance.\"\"\"\n",
    "    if mean is None and std is None:\n",
    "        mean = np.mean(X, axis=0)\n",
    "        std = np.std(X, axis=0)\n",
    "    \n",
    "    # Avoid division by zero for features with zero variance\n",
    "    std[std == 0] = 1\n",
    "    \n",
    "    return (X - mean) / std\n",
    "\n",
    "def pca(X, n_components):\n",
    "    \"\"\"Reduce the dimensionality of data using PCA.\"\"\"\n",
    "    # Ensure X is a 2D array and contains no single float values\n",
    "    if len(X.shape) != 2:\n",
    "        raise ValueError(\"Input data must be a 2D array.\")\n",
    "    \n",
    "    # Ensure X contains only numerical values\n",
    "    if not np.issubdtype(X.dtype, np.number):\n",
    "        raise ValueError(\"Input data must contain only numerical values.\")\n",
    "    \n",
    "    # Step 1: Center the data (subtract the mean of each feature)\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    \n",
    "    # Step 2: Compute the covariance matrix\n",
    "    covariance_matrix = np.cov(X_centered, rowvar=False)\n",
    "\n",
    "    \n",
    "    # Step 3: Perform eigenvalue decomposition\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    \n",
    "    # Step 4: Sort the eigenvectors by the largest eigenvalues (descending order)\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    top_eigenvectors = eigenvectors[:, sorted_indices[:n_components]]\n",
    "    \n",
    "    # Step 5: Project the data onto the top eigenvectors (principal components)\n",
    "    X_reduced = np.dot(X_centered, top_eigenvectors)\n",
    "    \n",
    "    return X_reduced\n",
    "\n",
    "\n",
    "def preprocess_data(train_path, test_path, scaling_type='none', apply_pca=False, n_components=None):\n",
    "    \n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "\n",
    "    # Separate features and target variable in training data\n",
    "    #X_train = train_data.drop(columns=['id', 'CustomerId', 'Surname', 'Exited'])\n",
    "    X_train = train_data.drop(columns=['Surname','id', 'CustomerId','Exited'])\n",
    "    y_train = train_data['Exited']\n",
    "\n",
    "    # Separate features in testing data\n",
    "    #X_test = test_data.drop(columns=['id', 'CustomerId', 'Surname'])\n",
    "    X_test = test_data.drop(columns=['Surname','id', 'CustomerId','CreditScore','Tenure','EstimatedSalary'])\n",
    "\n",
    "    # Define numerical, categorical, and binary columns\n",
    "    numerical_features = ['Age',  'Balance', 'NumOfProducts']\n",
    "    categorical_features = ['Geography']\n",
    "    binary_features = ['HasCrCard', 'IsActiveMember', 'Gender']\n",
    "\n",
    "    # Convert binary features to binary (0 or 1) encoding for Gender\n",
    "    X_train['Gender'] = X_train['Gender'].map({'Male': 0, 'Female': 1})\n",
    "    X_test['Gender'] = X_test['Gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "    # Preprocess numerical features (Impute missing values)\n",
    "    X_train_numerical = X_train[numerical_features].apply(impute_mean, axis=0)\n",
    "    X_test_numerical = X_test[numerical_features].apply(impute_mean, axis=0)\n",
    "\n",
    "    # Scaling options: standard or minmax\n",
    "    if scaling_type == 'standard':\n",
    "        X_train_numerical = standard_scale(X_train_numerical.to_numpy())\n",
    "        X_test_numerical = standard_scale(X_test_numerical.to_numpy())\n",
    "    elif scaling_type == 'minmax':\n",
    "        X_train_numerical = min_max_scale(X_train_numerical)\n",
    "        X_test_numerical = min_max_scale(X_test_numerical)\n",
    "\n",
    "    # Convert scaled numpy arrays back to DataFrame for consistency\n",
    "    X_train_numerical = pd.DataFrame(X_train_numerical, columns=numerical_features)\n",
    "    X_test_numerical = pd.DataFrame(X_test_numerical, columns=numerical_features)\n",
    "\n",
    "    # Apply one-hot encoding to categorical features (e.g., Geography)\n",
    "    X_train = one_hot_encode(X_train, categorical_features)\n",
    "    X_test = one_hot_encode(X_test, categorical_features)\n",
    "\n",
    "    # Convert boolean columns to integers for PCA compatibility\n",
    "    bool_columns = X_train.select_dtypes(include=['bool']).columns\n",
    "    X_train[bool_columns] = X_train[bool_columns].astype(int)\n",
    "    X_test[bool_columns] = X_test[bool_columns].astype(int)\n",
    "\n",
    "    # Dynamically select important categorical features if they exist after one-hot encoding\n",
    "    important_categorical_features = [col for col in X_train.columns if 'Geography' in col]\n",
    "\n",
    "    # Combine numerical, categorical, and binary features again\n",
    "    #X_train[important_categorical_features],\n",
    "    #X_test[important_categorical_features],\n",
    "    X_train = pd.concat([X_train_numerical,  X_train[binary_features]], axis=1)\n",
    "    X_test = pd.concat([X_test_numerical,   X_test[binary_features]], axis=1)\n",
    "\n",
    "    # Align train and test columns (some columns might appear only in one set after one-hot encoding)\n",
    "    X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "\n",
    "    # Apply PCA if specified\n",
    "    if apply_pca and n_components is not None:\n",
    "        X_train = pca(X_train.to_numpy(), n_components)\n",
    "        X_test = pca(X_test.to_numpy(), n_components)\n",
    "\n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to compute roc auc scores\n",
    "def roc_auc_score(y_true, y_pred):\n",
    "    \"\"\"Compute ROC AUC score from binary classification.\"\"\"\n",
    "    # Ensure inputs are numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Compute the number of positive and negative examples\n",
    "    pos = sum(y_true == 1)\n",
    "    neg = sum(y_true == 0)\n",
    "\n",
    "    # Edge case: If there are no positive or negative samples, AUC is undefined\n",
    "    if pos == 0 or neg == 0:\n",
    "        return 0.5  # Arbitrary, AUC cannot be computed meaningfully without both classes\n",
    "\n",
    "    # Initialize true positive rate (TPR) and false positive rate (FPR)\n",
    "    tpr = 0\n",
    "    fpr = 0\n",
    "\n",
    "    # Calculate TPR and FPR for binary predictions\n",
    "    for i in range(len(y_true)):\n",
    "        if y_pred[i] == 1 and y_true[i] == 1:\n",
    "            tpr += 1 / pos  # True positive rate\n",
    "        elif y_pred[i] == 1 and y_true[i] == 0:\n",
    "            fpr += 1 / neg  # False positive rate\n",
    "\n",
    "    # The AUC in this case is simply TPR - FPR (this is simplified for binary predictions)\n",
    "    auc = (tpr - fpr) + 1  # Adjusted to give a range from 0 to 1\n",
    "\n",
    "    return auc / 2  # Normalize AUC to range between 0 and 1\n",
    "\n",
    "# Define cross-validation function\n",
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    # Convert y to a numpy array and reshape it for concatenation\n",
    "    y = np.array(y).reshape(-1, 1)  \n",
    "\n",
    "    # Combine X and y so they can be shuffled together\n",
    "    data = np.hstack((X, y))\n",
    "\n",
    "    # Shuffle the data randomly\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    # Split X and y back\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    # Determine fold size\n",
    "    fold_size = len(X) // n_splits\n",
    "\n",
    "    # List to store the AUC scores for each fold\n",
    "    auc_scores = []\n",
    "    for i in range(n_splits):\n",
    "        # Create validation set\n",
    "        X_val = X[i * fold_size:(i + 1) * fold_size]\n",
    "        y_val = y[i * fold_size:(i + 1) * fold_size]\n",
    "\n",
    "        # Create training set (everything except the validation set)\n",
    "        X_train = np.concatenate((X[:i * fold_size], X[(i + 1) * fold_size:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]), axis=0)\n",
    "\n",
    "        # Fit the KNN model on the training data\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        # Get predictions for the validation set (binary classification)\n",
    "        y_pred = knn.predict(X_val)\n",
    "\n",
    "        # Compute the ROC AUC score for the validation set\n",
    "        auc_score = roc_auc_score(y_val, y_pred)\n",
    "        auc_scores.append(auc_score)\n",
    "    # Return the average AUC score over all splits\n",
    "    return np.mean(auc_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000000000021\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "X_train = train_data.drop(columns=['Surname','Gender','Geography', 'Exited'])\n",
    "y_train = train_data['Exited']\n",
    "\n",
    "knn = KNN(k=1, distance_metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "auc_score = roc_auc_score(y_train, y_pred)\n",
    "\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: 0.5268704588906215  for n_components:  12  for k value:  10\n",
      "Cross-validation scores: 0.5269780681933083  for n_components:  12  for k value:  12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[457], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m2\u001b[39m):  \u001b[38;5;66;03m# Try different values of k\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         knn \u001b[38;5;241m=\u001b[39m KNN(k\u001b[38;5;241m=\u001b[39mk, distance_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m         cv_score \u001b[38;5;241m=\u001b[39m cross_validate(X_train, y_train, knn)\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-validation scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv_score, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for n_components: \u001b[39m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for k value: \u001b[39m\u001b[38;5;124m\"\u001b[39m, k)\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cv_score \u001b[38;5;241m>\u001b[39m best_score:\n",
      "Cell \u001b[1;32mIn[408], line 65\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(X, y, knn, n_splits)\u001b[0m\n\u001b[0;32m     62\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Get predictions for the validation set (binary classification)\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Compute the ROC AUC score for the validation set\u001b[39;00m\n\u001b[0;32m     68\u001b[0m auc_score \u001b[38;5;241m=\u001b[39m roc_auc_score(y_val, y_pred)\n",
      "Cell \u001b[1;32mIn[388], line 18\u001b[0m, in \u001b[0;36mKNN.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     15\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Compute the distance matrix using the specified metric\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_distance(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[0;32m     20\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Loop through each test point to make predictions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[388], line 53\u001b[0m, in \u001b[0;36mKNN.compute_distance\u001b[1;34m(self, X1, X2)\u001b[0m\n\u001b[0;32m     50\u001b[0m cross_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X1, X2\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Step 3: Compute the full distance matrix\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m distances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(X_test_squared \u001b[38;5;241m+\u001b[39m X_train_squared \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m cross_term)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distances\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "#X_train, X_test, y_train = preprocess_data('train.csv', 'test.csv')\n",
    "#for i in range (2, 13):\n",
    "\n",
    "    # Create and evaluate model\n",
    "#    knn = KNN(k=7, distance_metric='euclidean')\n",
    "#    cv_scores = cross_validate(X_train, y_train, knn)\n",
    "\n",
    "#    print(\"Cross-validation scores:\", cv_scores)\n",
    "# Perform cross-validation using the training data (X_train, y_train)\n",
    "\n",
    "# TODO: hyperparamters tuning\n",
    "# TODO: Hyperparameter tuning (this is an example grid search for optimal k)\n",
    "def permutation_feature_importance(X_train, y_train, knn_model, scoring_func, n_splits=5, n_repeats=5):\n",
    "    \"\"\"\n",
    "    Calculate feature importance using permutation and cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features (should be a DataFrame to access column names)\n",
    "    - y_train: Training labels\n",
    "    - knn_model: Fitted KNN model\n",
    "    - scoring_func: Function to compute model performance (e.g., ROC AUC, accuracy)\n",
    "    - n_splits: Number of cross-validation splits\n",
    "    - n_repeats: Number of times to shuffle each feature for stability\n",
    "    \n",
    "    Returns:\n",
    "    - feature_importances: A dictionary of feature importances.\n",
    "    \"\"\"\n",
    "    # Get baseline score using cross-validation\n",
    "    baseline_score = cross_validate(X_train.to_numpy(), y_train, knn_model, n_splits)\n",
    "    \n",
    "    feature_importances = {}\n",
    "    \n",
    "    for feature_idx in range(X_train.shape[1]):\n",
    "        # Save the original column\n",
    "        original_feature = X_train.iloc[:, feature_idx].copy()\n",
    "        \n",
    "        # Shuffle the feature n_repeats times and evaluate performance\n",
    "        shuffled_scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_train.iloc[:, feature_idx] = np.random.permutation(X_train.iloc[:, feature_idx].values)\n",
    "            shuffled_score = cross_validate(X_train.to_numpy(), y_train, knn_model, n_splits)\n",
    "            shuffled_scores.append(shuffled_score)\n",
    "        \n",
    "        # Restore the original feature values\n",
    "        X_train.iloc[:, feature_idx] = original_feature\n",
    "        \n",
    "        # Calculate the importance as the difference between baseline and shuffled performance\n",
    "        feature_importance = baseline_score - np.mean(shuffled_scores)\n",
    "        feature_importances[X_train.columns[feature_idx]] = feature_importance\n",
    "    \n",
    "    return feature_importances\n",
    "\n",
    "    \n",
    "# Print out the feature importances\n",
    "#feature_importances = permutation_feature_importance(X_train, y_train, knn, roc_auc_score, n_splits=5)\n",
    "\n",
    "# Print out the feature importances\n",
    "#sorted_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "#print(\"Feature Importances (sorted):\")\n",
    "#for feature, importance in sorted_importances:\n",
    "#    print(f\"{feature}: {importance}\")\n",
    "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
    "best_k = None\n",
    "best_score = 0\n",
    "best_n = 0\n",
    "X_train, X_test, y_train = preprocess_data('train.csv', 'test.csv', scaling_type = 'standard', apply_pca=False, n_components=2)\n",
    "for k in range(10, 17, 2):  # Try different values of k\n",
    "        knn = KNN(k=k, distance_metric='euclidean')\n",
    "        cv_score = cross_validate(X_train, y_train, knn)\n",
    "        print(\"Cross-validation scores:\", cv_score, \" for n_components: \", i, \" for k value: \", k)\n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            best_k = k\n",
    "           # best_n = i\n",
    "\n",
    "\n",
    "#for i in range(6,13, 2):\n",
    "    \n",
    "    \n",
    "\n",
    "#test_predictions = knn.predict(X_test)\n",
    "\n",
    "# Save test predictions\n",
    "#pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7911874557377648 8 8\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_k,best_n)\n",
    "#with standard scaling values of 8 did well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7911874557377648 8 8\n"
     ]
    }
   ],
   "source": [
    "print(best_score,best_k,best_n)\n",
    "#without standard scaling values of 8 did well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
